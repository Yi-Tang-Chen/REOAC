seed: 0

logging:
  output_dir: runs
  exp_name: reoac_default
  checkpoint_interval: 5
  save_backbone: false
  save_actor_critic: true

dataset:
  task: gsm8k
  train_path: dataset/processed/gsm8k_train.jsonl
  eval_path: dataset/processed/gsm8k_test.jsonl
  raw_train_path: dataset/raw/gsm8k_train.jsonl
  raw_eval_path: dataset/raw/gsm8k_test.jsonl
  prompt_field: prompt
  answer_field: target_answer
  allow_toy: false
  download_on_missing: false
  hf_dataset: openai/gsm8k
  hf_config: main

backbone:
  name: e2d2
  model_name_or_path: kuleshov-group/e2d2-owt
  tokenizer_name_or_path: gpt2
  tokenizer_fallback: gpt2
  tokenizer_source: e2d2
  suppress_load_warnings: true
  max_length: 256
  sample_strategy: sample
  torch_dtype: null
  num_steps: 512
  sigma_schedule: cosine # or linear
  sigma_max: 1.0
  sigma_min: 0.0

rollout:
  max_steps: 512
  gen_len: 128
  branch_steps: [8, 16, 24, 32, 40, 48, 56]
  branch_k: 3
  selection_mode: sample
  seed: 0
  use_hidden: true
  cost_lambda: 0.01
  batch_size: 16
  fast_critic: false
  gpu_critic: true
  save_relation: true
  fast_operator: false
  ensure_update: true
  fallback_operator: O_FAST

finetune_mode: full
lora:
  r: 8
  alpha: 16
  dropout: 0.0
  target_modules: []

losses:
  critic_weight: 1.0
  actor_weight: 1.0
  backbone_weight: 1.1
  actor_temperature: 1.1
  advantage_positive: true
  advantage_clip: 0.1

optim:
  actor_lr: 1.0e-4
  critic_lr: 1.0e-4
  backbone_lr: 5.0e-6

update:
  critic_steps: 2
  actor_steps: 1
  backbone_steps: 1

buffer_size: 100
num_iterations: 25
episodes_per_iter: 8

eval:
  math_parser: latex2sympy2

reward:
  mode: shaped
